{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf31290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823faf54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#   EXPLORATORY DATA ANALYSIS   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ade1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('...\\\\AUTISM_SCREENING_FOR_TODDLERS\\\\archive')\n",
    "df = pd.read_csv('../../data/Toddler_Autism_dataset_July_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68853b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case_No', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',\n",
       "       'Age_Mons', 'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice',\n",
       "       'Family_mem_with_ASD', 'Who completed the test', 'Class/ASD Traits '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9c0d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5cb487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has 1054 rows and 19 columns\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "print(f\"The df has {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ad7456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  target  \n",
       "0     No  \n",
       "1    Yes  \n",
       "2    Yes  \n",
       "3    Yes  \n",
       "4    Yes  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns ={\"Class/ASD Traits \":\"target\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1826874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target = np.where(df.target =='Yes',1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15860f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>543.781593</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.603022</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.712912</td>\n",
       "      <td>0.765110</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.682692</td>\n",
       "      <td>0.645604</td>\n",
       "      <td>28.223901</td>\n",
       "      <td>6.788462</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>291.080202</td>\n",
       "      <td>0.443865</td>\n",
       "      <td>0.489608</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>0.466286</td>\n",
       "      <td>0.452714</td>\n",
       "      <td>0.424222</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.489895</td>\n",
       "      <td>0.465748</td>\n",
       "      <td>0.478659</td>\n",
       "      <td>7.491995</td>\n",
       "      <td>1.921937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>544.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>789.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1054.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Case_No          A1          A2          A3          A4  \\\n",
       "count   728.000000  728.000000  728.000000  728.000000  728.000000   \n",
       "mean    543.781593    0.730769    0.603022    0.535714    0.681319   \n",
       "std     291.080202    0.443865    0.489608    0.499066    0.466286   \n",
       "min       2.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     302.750000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     544.500000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%     789.250000    1.000000    1.000000    1.000000    1.000000   \n",
       "max    1054.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               A5          A6          A7          A8          A9         A10  \\\n",
       "count  728.000000  728.000000  728.000000  728.000000  728.000000  728.000000   \n",
       "mean     0.712912    0.765110    0.829670    0.601648    0.682692    0.645604   \n",
       "std      0.452714    0.424222    0.376181    0.489895    0.465748    0.478659   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Age_Mons  Qchat-10-Score  target  \n",
       "count  728.000000      728.000000   728.0  \n",
       "mean    28.223901        6.788462     1.0  \n",
       "std      7.491995        1.921937     0.0  \n",
       "min     12.000000        4.000000     1.0  \n",
       "25%     24.000000        5.000000     1.0  \n",
       "50%     30.000000        7.000000     1.0  \n",
       "75%     36.000000        8.000000     1.0  \n",
       "max     36.000000       10.000000     1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes = df[df['target']==1]\n",
    "yes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa10f87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>543.781593</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.603022</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.712912</td>\n",
       "      <td>0.765110</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.682692</td>\n",
       "      <td>0.645604</td>\n",
       "      <td>28.223901</td>\n",
       "      <td>6.788462</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>291.080202</td>\n",
       "      <td>0.443865</td>\n",
       "      <td>0.489608</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>0.466286</td>\n",
       "      <td>0.452714</td>\n",
       "      <td>0.424222</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.489895</td>\n",
       "      <td>0.465748</td>\n",
       "      <td>0.478659</td>\n",
       "      <td>7.491995</td>\n",
       "      <td>1.921937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>544.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>789.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1054.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Case_No          A1          A2          A3          A4  \\\n",
       "count   728.000000  728.000000  728.000000  728.000000  728.000000   \n",
       "mean    543.781593    0.730769    0.603022    0.535714    0.681319   \n",
       "std     291.080202    0.443865    0.489608    0.499066    0.466286   \n",
       "min       2.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     302.750000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     544.500000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%     789.250000    1.000000    1.000000    1.000000    1.000000   \n",
       "max    1054.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               A5          A6          A7          A8          A9         A10  \\\n",
       "count  728.000000  728.000000  728.000000  728.000000  728.000000  728.000000   \n",
       "mean     0.712912    0.765110    0.829670    0.601648    0.682692    0.645604   \n",
       "std      0.452714    0.424222    0.376181    0.489895    0.465748    0.478659   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Age_Mons  Qchat-10-Score  target  \n",
       "count  728.000000      728.000000   728.0  \n",
       "mean    28.223901        6.788462     1.0  \n",
       "std      7.491995        1.921937     0.0  \n",
       "min     12.000000        4.000000     1.0  \n",
       "25%     24.000000        5.000000     1.0  \n",
       "50%     30.000000        7.000000     1.0  \n",
       "75%     36.000000        8.000000     1.0  \n",
       "max     36.000000       10.000000     1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes = df[df['target']==1]\n",
    "yes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b799ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>491.141104</td>\n",
       "      <td>0.190184</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>0.101227</td>\n",
       "      <td>0.134969</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>0.156442</td>\n",
       "      <td>0.248466</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>27.070552</td>\n",
       "      <td>1.693252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>329.822300</td>\n",
       "      <td>0.393050</td>\n",
       "      <td>0.306112</td>\n",
       "      <td>0.302093</td>\n",
       "      <td>0.342216</td>\n",
       "      <td>0.306112</td>\n",
       "      <td>0.363832</td>\n",
       "      <td>0.432788</td>\n",
       "      <td>0.348664</td>\n",
       "      <td>0.234636</td>\n",
       "      <td>0.498644</td>\n",
       "      <td>8.936593</td>\n",
       "      <td>1.066014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>173.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>472.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>796.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1053.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Case_No          A1          A2          A3          A4  \\\n",
       "count   326.000000  326.000000  326.000000  326.000000  326.000000   \n",
       "mean    491.141104    0.190184    0.104294    0.101227    0.134969   \n",
       "std     329.822300    0.393050    0.306112    0.302093    0.342216   \n",
       "min       1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     173.250000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     472.500000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     796.750000    0.000000    0.000000    0.000000    0.000000   \n",
       "max    1053.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               A5          A6          A7          A8          A9         A10  \\\n",
       "count  326.000000  326.000000  326.000000  326.000000  326.000000  326.000000   \n",
       "mean     0.104294    0.156442    0.248466    0.141104    0.058282    0.453988   \n",
       "std      0.306112    0.363832    0.432788    0.348664    0.234636    0.498644   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Age_Mons  Qchat-10-Score  target  \n",
       "count  326.000000      326.000000   326.0  \n",
       "mean    27.070552        1.693252     0.0  \n",
       "std      8.936593        1.066014     0.0  \n",
       "min     12.000000        0.000000     0.0  \n",
       "25%     19.000000        1.000000     0.0  \n",
       "50%     30.000000        2.000000     0.0  \n",
       "75%     36.000000        3.000000     0.0  \n",
       "max     36.000000        3.000000     0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no = df[df['target']==0]\n",
    "no.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79ac170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1054.000000</td>\n",
       "      <td>1054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690702</td>\n",
       "      <td>5.212524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.462424</td>\n",
       "      <td>2.907304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  Qchat-10-Score\n",
       "count  1054.000000     1054.000000\n",
       "mean      0.690702        5.212524\n",
       "std       0.462424        2.907304\n",
       "min       0.000000        0.000000\n",
       "25%       0.000000        3.000000\n",
       "50%       1.000000        5.000000\n",
       "75%       1.000000        8.000000\n",
       "max       1.000000       10.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The minimum value of Qchat-10-Score variable for yes(1) (autistic) is 4.\n",
    "The maximum value of Qchat-10-Score variable for no(0) (non-autistic) is 3.\n",
    "\"\"\"\n",
    "df1 = df[['target','Qchat-10-Score']]\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c030fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1054.000000</td>\n",
       "      <td>1054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690702</td>\n",
       "      <td>5.212524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.462424</td>\n",
       "      <td>2.907304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  Qchat-10-Score\n",
       "count  1054.000000     1054.000000\n",
       "mean      0.690702        5.212524\n",
       "std       0.462424        2.907304\n",
       "min       0.000000        0.000000\n",
       "25%       0.000000        3.000000\n",
       "50%       1.000000        5.000000\n",
       "75%       1.000000        8.000000\n",
       "max       1.000000       10.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The minimum value of Qchat-10-Score variable for yes(1) (autistic) is 4.\n",
    "The maximum value of Qchat-10-Score variable for no(0) (non-autistic) is 3.\n",
    "\"\"\"\n",
    "df1 = df[['target','Qchat-10-Score']]\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e019f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <td>0.810423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  target  Qchat-10-Score\n",
       "target          1.000000        0.810423\n",
       "Qchat-10-Score  0.810423        1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.corr()# 81 % correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea08e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_yes = df1[df1['Qchat-10-Score'] >3]\n",
    "df1_no = df1[df1['Qchat-10-Score'] <=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f30278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>728.0</td>\n",
       "      <td>728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.921937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  Qchat-10-Score\n",
       "count   728.0      728.000000\n",
       "mean      1.0        6.788462\n",
       "std       0.0        1.921937\n",
       "min       1.0        4.000000\n",
       "25%       1.0        5.000000\n",
       "50%       1.0        7.000000\n",
       "75%       1.0        8.000000\n",
       "max       1.0       10.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_yes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "769719a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>326.0</td>\n",
       "      <td>326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.693252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.066014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  Qchat-10-Score\n",
       "count   326.0      326.000000\n",
       "mean      0.0        1.693252\n",
       "std       0.0        1.066014\n",
       "min       0.0        0.000000\n",
       "25%       0.0        1.000000\n",
       "50%       0.0        2.000000\n",
       "75%       0.0        3.000000\n",
       "max       0.0        3.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_no.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd032c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_yes.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f480e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_no.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de014b81",
   "metadata": {},
   "source": [
    "#### The result shows that for:\n",
    "    Qchat-10-Score >3 target variable is 1 i.e. patient has autism.\n",
    "    Qchat-10-Score <=3 target variable is 0 i.e. patient does not have autism.\n",
    "    \n",
    "So by just using this information i.e. with just the Qchat-10-Score variable \n",
    "and the cut of value of 3, we can correctly predict whether a toddler has autism \n",
    "or not. This is a classical case of data leakage that is the independent \n",
    "variable contains information about the target variable hence when ever we train\n",
    "the model if the train test split is done in such a way that the model recognizes\n",
    "this information then we will almost everytime get a very high score. We may be\n",
    "happy that our model is doing so well. In real lif when new dataset comes it may\n",
    "not contain this information in the Qchat-10-Score variable and hence our model\n",
    "may not perform well. \n",
    "To check this let us :\n",
    "    1.first train the model with the Qchat-10-Score variable on the toddler \n",
    "    dataset and validate our model on the git hub data set. \n",
    "    2. secondly train the model without the Qchat-10-Score variable on the\n",
    "    toddler dataset and validate our model on the git hub data set.\n",
    "    3. thirdly train the model with the Qchat-10-Score variable on the combined \n",
    "    dataset and validate our model on the combined data set. \n",
    "    $. fourthly train the model without the Qchat-10-Score variable on the combined \n",
    "    dataset and validate our model on the combined data set. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd0fe0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    728\n",
       " Name: target, dtype: int64,\n",
       " 0    326\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1_yes.target.value_counts(), df1_no.target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb5dda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    #Get the new dataset from github\n",
    "    # os.chdir(r'...\\AUTISM_SCREENING_FOR_TODDLERS\\archive\\github_data\\Data-Analytics-model-on-Behavioural-Challenges-of-ASD-kids')\n",
    "    # os.listdir()\n",
    "    dff = pd.read_csv('../../data/data_csv.csv')\n",
    "    dff['Sex'] = np.where(dff['Sex']=='F','f','m')\n",
    "    dff1 = dff[[ 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8','A9', 'A10_Autism_Spectrum_Quotient','Age_Years', 'Qchat_10_Score',  'Sex', 'Ethnicity', 'Jaundice','Family_mem_with_ASD', 'Who_completed_the_test', 'ASD_traits']]\n",
    "    #max age in toddlers dataset is 36 months i.e. 3 years\n",
    "    df.Age_Mons.max()\n",
    "    #filter from the new data all records with 'Age_Years' <= 3\n",
    "    dff2 = dff1[dff1['Age_Years']<=3]\n",
    "    yes = dff2[dff2['ASD_traits']=='Yes']\n",
    "    yes.describe()\n",
    "    no = dff2[dff2['ASD_traits']=='No']\n",
    "    a = df[['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10','Age_Mons', 'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test', 'target']]\n",
    "    b = dff2\n",
    "    b.columns\n",
    "    b.rename(columns={'A10_Autism_Spectrum_Quotient':'A10'},inplace = True)\n",
    "    b.rename(columns = {'ASD_traits':'target'},inplace = True)\n",
    "    b['Age_Mons']=b.Age_Years*12\n",
    "    #b.drop(['Qchat_10_Score','Age_Years'],axis=1,inplace = True)\n",
    "    b.drop(['Age_Years'],axis=1,inplace = True)\n",
    "    b.target = np.where(b['target'] == 'Yes',1,0)\n",
    "    a.rename(columns = {'Who completed the test':'Who_completed_the_test'},inplace = True)\n",
    "    a.rename(columns = {'Qchat-10-Score':'Qchat_10_Score'},inplace = True)\n",
    "    b = b[['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons','Qchat_10_Score','Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD','Who_completed_the_test', 'target']]\n",
    "    b.columns\n",
    "    a.columns\n",
    "    b['Qchat_10_Score'] = b['Qchat_10_Score'].fillna(0).astype(np.int64)\n",
    "    a['dataset']='toddler'\n",
    "    b['dataset']='github'\n",
    "    c=a.append(b)\n",
    "    ### save the preprocessed files\n",
    "    a.to_csv(r'../../data/pre_processed/original_data.csv',index = False)\n",
    "    b.to_csv(r'../../data/pre_processed/github_data.csv',index = False)\n",
    "    c.to_csv(r'../../data/pre_processed/combined_data.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbf7f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb3918",
   "metadata": {},
   "source": [
    "#### Read the files saved from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580bb0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
       "        'Who_completed_the_test', 'target', 'dataset'],\n",
       "       dtype='object'),\n",
       " Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
       "        'Who_completed_the_test', 'target', 'dataset'],\n",
       "       dtype='object'),\n",
       " Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
       "        'Who_completed_the_test', 'target', 'dataset'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = pd.read_csv(r'../../data/pre_processed/original_data.csv')\n",
    "bb = pd.read_csv(r'../../data/pre_processed/github_data.csv')\n",
    "cc = pd.read_csv(r'../../data/pre_processed/combined_data.csv')\n",
    "aa.columns, bb.columns, cc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e7089",
   "metadata": {},
   "source": [
    "#### Create dummy variable for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f4c400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df):\n",
    "    #Introducing dummy variables for all categorical variables by dropping the first dummy variable\n",
    "    Sex = pd.get_dummies(df.Sex, prefix='Sex', drop_first=True)\n",
    "    Ethnicity = pd.get_dummies(df.Ethnicity, prefix='Ethnicity', drop_first=True)\n",
    "    Jaundice = pd.get_dummies(df.Jaundice, prefix='Jaundice', drop_first=True)\n",
    "    Family_mem_with_ASD = pd.get_dummies(df.Family_mem_with_ASD, prefix='Family_mem_with_ASD', drop_first=True)\n",
    "    Who_completed_the_test = pd.get_dummies(df[\"Who_completed_the_test\"], prefix='Who_completed_the_test', drop_first=True)\n",
    "    #Introducing dummy variables for all categorical variables by dropping the first dummy variable\n",
    "    df.drop([\"Sex\",\"Ethnicity\",\"Jaundice\",\"Family_mem_with_ASD\",\"Who_completed_the_test\"], axis = 1,inplace=True)\n",
    "    df =  pd.concat([df, Sex,Ethnicity,Jaundice,Family_mem_with_ASD,Who_completed_the_test ], axis=1)\n",
    "    return(df)\n",
    "\n",
    "def save_files():\n",
    "    aaa = get_dummy(aa)\n",
    "    bbb = get_dummy(bb)\n",
    "    ccc = get_dummy(cc)\n",
    "    aaa.columns\n",
    "    bbb.columns\n",
    "    ccc.columns\n",
    "\n",
    "    aaa.to_csv(r'../../data/pre_processed/original_data_one_hot_encoded.csv',index = False)\n",
    "    bbb.to_csv(r'../../data/pre_processed/github_data_one_hot_encoded.csv',index = False)\n",
    "    ccc.to_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3102aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425f7589",
   "metadata": {},
   "source": [
    "# END OF EXPLORATORY DATA ANALYSIS  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f061be",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21e644",
   "metadata": {},
   "source": [
    "# Train the model to see the effect of Qchat-10-Score variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abfd81",
   "metadata": {},
   "source": [
    "#### Read the files saved one hot encoded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beb04f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.read_csv(r'../../data/pre_processed/original_data_one_hot_encoded.csv')\n",
    "bb = pd.read_csv(r'../../data/pre_processed/github_data_one_hot_encoded.csv')\n",
    "cc = pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "947bb8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'target', 'dataset', 'Sex_m', 'Ethnicity_Latino',\n",
       "        'Ethnicity_Native Indian', 'Ethnicity_Others', 'Ethnicity_Pacifica',\n",
       "        'Ethnicity_White European', 'Ethnicity_asian', 'Ethnicity_black',\n",
       "        'Ethnicity_middle eastern', 'Ethnicity_mixed', 'Ethnicity_south asian',\n",
       "        'Jaundice_yes', 'Family_mem_with_ASD_yes',\n",
       "        'Who_completed_the_test_Health care professional',\n",
       "        'Who_completed_the_test_Others', 'Who_completed_the_test_Self',\n",
       "        'Who_completed_the_test_family member'],\n",
       "       dtype='object'),\n",
       " Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'target', 'dataset', 'Sex_m', 'Ethnicity_Black',\n",
       "        'Ethnicity_Hispanic', 'Ethnicity_Latino', 'Ethnicity_Middle Eastern',\n",
       "        'Ethnicity_Mixed', 'Ethnicity_Native Indian', 'Ethnicity_Others',\n",
       "        'Ethnicity_South Asian', 'Ethnicity_White European', 'Ethnicity_asian',\n",
       "        'Ethnicity_black', 'Ethnicity_middle eastern', 'Ethnicity_south asian',\n",
       "        'Jaundice_Yes', 'Family_mem_with_ASD_Yes',\n",
       "        'Who_completed_the_test_Family member',\n",
       "        'Who_completed_the_test_Health Care Professional'],\n",
       "       dtype='object'),\n",
       " Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "        'Qchat_10_Score', 'target', 'dataset', 'Sex_m', 'Ethnicity_Black',\n",
       "        'Ethnicity_Hispanic', 'Ethnicity_Latino', 'Ethnicity_Middle Eastern',\n",
       "        'Ethnicity_Mixed', 'Ethnicity_Native Indian', 'Ethnicity_Others',\n",
       "        'Ethnicity_Pacifica', 'Ethnicity_South Asian',\n",
       "        'Ethnicity_White European', 'Ethnicity_asian', 'Ethnicity_black',\n",
       "        'Ethnicity_middle eastern', 'Ethnicity_mixed', 'Ethnicity_south asian',\n",
       "        'Jaundice_Yes', 'Jaundice_no', 'Jaundice_yes',\n",
       "        'Family_mem_with_ASD_Yes', 'Family_mem_with_ASD_no',\n",
       "        'Family_mem_with_ASD_yes', 'Who_completed_the_test_Family member',\n",
       "        'Who_completed_the_test_Health Care Professional',\n",
       "        'Who_completed_the_test_Health care professional',\n",
       "        'Who_completed_the_test_Others', 'Who_completed_the_test_Self',\n",
       "        'Who_completed_the_test_family member'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.columns, bb.columns, cc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b35571ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1054, 31), (147, 32), (1201, 42))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape, bb.shape, cc.shape # (147, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b68a9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions to train the models\n",
    "def train_model1(df1,test_size):\n",
    "    df1.drop('dataset',axis = 1, inplace=True)\n",
    "    # Putting feature variable to X\n",
    "    X = df1.drop(['target'], axis=1)\n",
    "    # Puttting response variable to y\n",
    "    y = df1.loc[:,['target']]\n",
    "\n",
    "    # Splitting the data into train and test with test size as 30% and random state as 101\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= test_size)\n",
    "    # Pipeline Estimator \n",
    "    standardscaler =StandardScaler()\n",
    "    radomforestclassifier = RandomForestClassifier(n_jobs = -1,verbose = 0)\n",
    "    pipeline = make_pipeline(standardscaler,radomforestclassifier)\n",
    "    # fit model on training data\n",
    "    pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    # Predict the sales of the test data\n",
    "    y_test['pred'] = pipeline.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # testing score\n",
    "    score = metrics.f1_score(y_test['target'], y_test['pred'],labels=None, pos_label=1)\n",
    "\n",
    "    print(\"F1 score for test data is : \",score)\n",
    "    print(\"Accuracy score for test data is : \",metrics.accuracy_score(y_test['target'], y_test['pred']))\n",
    "    print('train_test_split_ratio is : ', test_size)\n",
    "\n",
    "\n",
    "def train_model2(df1,df2):\n",
    "    # Putting feature variable to X\n",
    "    X_train = df1.drop(['target'], axis=1)\n",
    "    # Puttting response variable to y\n",
    "    y_train = df1.loc[:,['target']]\n",
    "\n",
    "\n",
    "    # Putting feature variable to X\n",
    "    X_test = df2.drop(['target'], axis=1)\n",
    "    # Puttting response variable to y\n",
    "    y_test = df2.loc[:,['target']]\n",
    "\n",
    "\n",
    "    standardscaler =StandardScaler()\n",
    "    radomforestclassifier = RandomForestClassifier(n_jobs = -1,verbose = 0)\n",
    "    pipeline = make_pipeline(standardscaler,radomforestclassifier)\n",
    "    # fit model on training data\n",
    "    pipeline.fit(X_train,y_train)\n",
    "\n",
    "    #Test data is the github dataset\n",
    "    X_test.columns\n",
    "\n",
    "\n",
    "    # Predict the sales of the test data\n",
    "    y_test['pred'] = pipeline.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # testing score\n",
    "    score = metrics.f1_score(y_test['target'], y_test['pred'],labels=None, pos_label=1)\n",
    "\n",
    "    print(\"F1 score for test data is : \",score)\n",
    "    print(\"Accuracy score for test data is : \",metrics.accuracy_score(y_test['target'], y_test['pred']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac2585ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nF1 score for test data is :  1.0\\nAccuracy score for test data is :  1.0\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# 1. First train the model with the Qchat-10-Score variable on the toddler \n",
    "#    dataset and validate our model on the test data of the toddler data set. \n",
    "###########################################################################################################################\n",
    "df1 = pd.read_csv(r'../../data/pre_processed/original_data_one_hot_encoded.csv')\n",
    "train_model1(df1, test_size=0.25)\n",
    "\n",
    "#Result\n",
    "\"\"\"\n",
    "F1 score for test data is :  1.0\n",
    "Accuracy score for test data is :  1.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "283b4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test data is :  0.8488372093023255\n",
      "Accuracy score for test data is :  0.8231292517006803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nF1 score for test data is :  0.8488372093023255\\nAccuracy score for test data is :  0.8231292517006803\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "# 2. Secondly train the model with the Qchat-10-Score variable on the toddler \n",
    "#    dataset and validate our model on the git hub data set. \n",
    "###########################################################################################################################\n",
    "\n",
    "df =  pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')\n",
    "df1 = df[df['dataset']=='toddler']\n",
    "df2 = df[df['dataset']=='github']\n",
    "df1.drop('dataset',axis = 1, inplace=True)\n",
    "df2.drop('dataset',axis = 1, inplace=True)\n",
    "\n",
    "train_model2(df1, df2)\n",
    "#Result\n",
    "\"\"\"\n",
    "F1 score for test data is :  0.8488372093023255\n",
    "Accuracy score for test data is :  0.8231292517006803\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e34a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test data is :  0.9403973509933775\n",
      "Accuracy score for test data is :  0.9387755102040817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nF1 score for test data is :  0.9466666666666668\\nAccuracy score for test data is :  0.9455782312925171\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "# 3. Thirdly train the model without the Qchat-10-Score variable on the toddler \n",
    "#    dataset and validate our model on the git hub data set. \n",
    "###########################################################################################################################\n",
    "\n",
    "df =  pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')\n",
    "df.drop('Qchat_10_Score',axis = 1, inplace=True)\n",
    "df1 = df[df['dataset']=='toddler']\n",
    "df2 = df[df['dataset']=='github']\n",
    "df1.drop('dataset',axis = 1, inplace=True)\n",
    "df2.drop('dataset',axis = 1, inplace=True)\n",
    "\n",
    "train_model2(df1, df2)\n",
    "# Result\n",
    "\"\"\"\n",
    "F1 score for test data is :  0.9466666666666668\n",
    "Accuracy score for test data is :  0.9455782312925171\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "366b8e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.1\n",
      " Value of i is : 10\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.11\n",
      " Value of i is : 11\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.12\n",
      " Value of i is : 12\n",
      "F1 score for test data is :  0.9949238578680203\n",
      "Accuracy score for test data is :  0.9936305732484076\n",
      "train_test_split_ratio is :  0.13\n",
      " Value of i is : 13\n",
      "F1 score for test data is :  0.995433789954338\n",
      "Accuracy score for test data is :  0.9940828402366864\n",
      "train_test_split_ratio is :  0.14\n",
      " Value of i is : 14\n",
      "F1 score for test data is :  0.9960159362549801\n",
      "Accuracy score for test data is :  0.994475138121547\n",
      "train_test_split_ratio is :  0.15\n",
      " Value of i is : 15\n",
      "F1 score for test data is :  0.9925925925925926\n",
      "Accuracy score for test data is :  0.9896373056994818\n",
      "train_test_split_ratio is :  0.16\n",
      " Value of i is : 16\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.17\n",
      " Value of i is : 17\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.18\n",
      " Value of i is : 18\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.19\n",
      " Value of i is : 19\n",
      "F1 score for test data is :  0.9969788519637462\n",
      "Accuracy score for test data is :  0.995850622406639\n",
      "train_test_split_ratio is :  0.2\n",
      " Value of i is : 20\n",
      "F1 score for test data is :  0.9970501474926253\n",
      "Accuracy score for test data is :  0.9960474308300395\n",
      "train_test_split_ratio is :  0.21\n",
      " Value of i is : 21\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.22\n",
      " Value of i is : 22\n",
      "F1 score for test data is :  0.9974160206718347\n",
      "Accuracy score for test data is :  0.9963898916967509\n",
      "train_test_split_ratio is :  0.23\n",
      " Value of i is : 23\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.24\n",
      " Value of i is : 24\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.25\n",
      " Value of i is : 25\n",
      "F1 score for test data is :  0.9975669099756691\n",
      "Accuracy score for test data is :  0.9968051118210862\n",
      "train_test_split_ratio is :  0.26\n",
      " Value of i is : 26\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.27\n",
      " Value of i is : 27\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.28\n",
      " Value of i is : 28\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.29\n",
      " Value of i is : 29\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.3\n",
      " Value of i is : 30\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.31\n",
      " Value of i is : 31\n",
      "F1 score for test data is :  0.9981851179673321\n",
      "Accuracy score for test data is :  0.9974025974025974\n",
      "train_test_split_ratio is :  0.32\n",
      " Value of i is : 32\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.33\n",
      " Value of i is : 33\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.34\n",
      " Value of i is : 34\n",
      "F1 score for test data is :  0.9982728842832469\n",
      "Accuracy score for test data is :  0.997624703087886\n",
      "train_test_split_ratio is :  0.35000000000000003\n",
      " Value of i is : 35\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.36\n",
      " Value of i is : 36\n",
      "F1 score for test data is :  0.9933774834437086\n",
      "Accuracy score for test data is :  0.9910112359550561\n",
      "train_test_split_ratio is :  0.37\n",
      " Value of i is : 37\n",
      "F1 score for test data is :  0.9984202211690364\n",
      "Accuracy score for test data is :  0.9978118161925602\n",
      "train_test_split_ratio is :  0.38\n",
      " Value of i is : 38\n",
      "F1 score for test data is :  0.9982728842832469\n",
      "Accuracy score for test data is :  0.997867803837953\n",
      "train_test_split_ratio is :  0.39\n",
      " Value of i is : 39\n",
      "F1 score for test data is :  0.9984202211690364\n",
      "Accuracy score for test data is :  0.997920997920998\n",
      "train_test_split_ratio is :  0.4\n",
      " Value of i is : 40\n",
      "F1 score for test data is :  1.0\n",
      "Accuracy score for test data is :  1.0\n",
      "train_test_split_ratio is :  0.41000000000000003\n",
      " Value of i is : 41\n",
      "F1 score for test data is :  0.9985652797704447\n",
      "Accuracy score for test data is :  0.998019801980198\n",
      "train_test_split_ratio is :  0.42\n",
      " Value of i is : 42\n",
      "F1 score for test data is :  0.9985315712187959\n",
      "Accuracy score for test data is :  0.9980657640232108\n",
      "train_test_split_ratio is :  0.43\n",
      " Value of i is : 43\n",
      "F1 score for test data is :  0.9986013986013986\n",
      "Accuracy score for test data is :  0.998109640831758\n",
      "train_test_split_ratio is :  0.44\n",
      " Value of i is : 44\n",
      "F1 score for test data is :  0.9972144846796658\n",
      "Accuracy score for test data is :  0.9963031423290203\n",
      "train_test_split_ratio is :  0.45\n",
      " Value of i is : 45\n",
      "F1 score for test data is :  0.9915730337078652\n",
      "Accuracy score for test data is :  0.9891500904159132\n",
      "train_test_split_ratio is :  0.46\n",
      " Value of i is : 46\n",
      "F1 score for test data is :  0.9972972972972972\n",
      "Accuracy score for test data is :  0.9964601769911504\n",
      "train_test_split_ratio is :  0.47000000000000003\n",
      " Value of i is : 47\n",
      "F1 score for test data is :  0.9947916666666666\n",
      "Accuracy score for test data is :  0.9930675909878682\n",
      "train_test_split_ratio is :  0.48\n",
      " Value of i is : 48\n",
      "F1 score for test data is :  0.9974811083123425\n",
      "Accuracy score for test data is :  0.9966044142614601\n",
      "train_test_split_ratio is :  0.49\n",
      " Value of i is : 49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################################################################################################\n",
    "# 4. Fourthly train the model with the Qchat-10-Score variable on the combined \n",
    "#    dataset and validate our model on the combined data set. \n",
    "###########################################################################################################################\n",
    "\n",
    "for i in range(10,50):\n",
    "    df1 =  pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')\n",
    "    train_model1(df1, test_size=i*0.01)\n",
    "    print(\" Value of i is :\", i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66536db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test data is :  0.9689440993788819\n",
      "Accuracy score for test data is :  0.9586776859504132\n",
      "train_test_split_ratio is :  0.1\n",
      " Value of i is : 10\n",
      "F1 score for test data is :  0.96045197740113\n",
      "Accuracy score for test data is :  0.9473684210526315\n",
      "train_test_split_ratio is :  0.11\n",
      " Value of i is : 11\n",
      "F1 score for test data is :  0.9852216748768472\n",
      "Accuracy score for test data is :  0.9793103448275862\n",
      "train_test_split_ratio is :  0.12\n",
      " Value of i is : 12\n",
      "F1 score for test data is :  0.9636363636363636\n",
      "Accuracy score for test data is :  0.9490445859872612\n",
      "train_test_split_ratio is :  0.13\n",
      " Value of i is : 13\n",
      "F1 score for test data is :  0.9865470852017937\n",
      "Accuracy score for test data is :  0.9822485207100592\n",
      "train_test_split_ratio is :  0.14\n",
      " Value of i is : 14\n",
      "F1 score for test data is :  0.962962962962963\n",
      "Accuracy score for test data is :  0.9502762430939227\n",
      "train_test_split_ratio is :  0.15\n",
      " Value of i is : 15\n",
      "F1 score for test data is :  0.9617021276595744\n",
      "Accuracy score for test data is :  0.9533678756476683\n",
      "train_test_split_ratio is :  0.16\n",
      " Value of i is : 16\n",
      "F1 score for test data is :  0.9811320754716981\n",
      "Accuracy score for test data is :  0.975609756097561\n",
      "train_test_split_ratio is :  0.17\n",
      " Value of i is : 17\n",
      "F1 score for test data is :  0.9770491803278688\n",
      "Accuracy score for test data is :  0.967741935483871\n",
      "train_test_split_ratio is :  0.18\n",
      " Value of i is : 18\n",
      "F1 score for test data is :  0.9704918032786886\n",
      "Accuracy score for test data is :  0.9606986899563319\n",
      "train_test_split_ratio is :  0.19\n",
      " Value of i is : 19\n",
      "F1 score for test data is :  0.977198697068404\n",
      "Accuracy score for test data is :  0.970954356846473\n",
      "train_test_split_ratio is :  0.2\n",
      " Value of i is : 20\n",
      "F1 score for test data is :  0.9567723342939481\n",
      "Accuracy score for test data is :  0.9407114624505929\n",
      "train_test_split_ratio is :  0.21\n",
      " Value of i is : 21\n",
      "F1 score for test data is :  0.9686609686609686\n",
      "Accuracy score for test data is :  0.9584905660377359\n",
      "train_test_split_ratio is :  0.22\n",
      " Value of i is : 22\n",
      "F1 score for test data is :  0.9871465295629821\n",
      "Accuracy score for test data is :  0.9819494584837545\n",
      "train_test_split_ratio is :  0.23\n",
      " Value of i is : 23\n",
      "F1 score for test data is :  0.9711286089238844\n",
      "Accuracy score for test data is :  0.9619377162629758\n",
      "train_test_split_ratio is :  0.24\n",
      " Value of i is : 24\n",
      "F1 score for test data is :  0.9707317073170731\n",
      "Accuracy score for test data is :  0.9601328903654485\n",
      "train_test_split_ratio is :  0.25\n",
      " Value of i is : 25\n",
      "F1 score for test data is :  0.9691211401425178\n",
      "Accuracy score for test data is :  0.9584664536741214\n",
      "train_test_split_ratio is :  0.26\n",
      " Value of i is : 26\n",
      "F1 score for test data is :  0.9669811320754718\n",
      "Accuracy score for test data is :  0.9569230769230769\n",
      "train_test_split_ratio is :  0.27\n",
      " Value of i is : 27\n",
      "F1 score for test data is :  0.9761388286334056\n",
      "Accuracy score for test data is :  0.9673590504451038\n",
      "train_test_split_ratio is :  0.28\n",
      " Value of i is : 28\n",
      "F1 score for test data is :  0.9645093945720251\n",
      "Accuracy score for test data is :  0.9512893982808023\n",
      "train_test_split_ratio is :  0.29\n",
      " Value of i is : 29\n",
      "F1 score for test data is :  0.960167714884696\n",
      "Accuracy score for test data is :  0.9473684210526315\n",
      "train_test_split_ratio is :  0.3\n",
      " Value of i is : 30\n",
      "F1 score for test data is :  0.9539078156312625\n",
      "Accuracy score for test data is :  0.938337801608579\n",
      "train_test_split_ratio is :  0.31\n",
      " Value of i is : 31\n",
      "F1 score for test data is :  0.9716446124763706\n",
      "Accuracy score for test data is :  0.961038961038961\n",
      "train_test_split_ratio is :  0.32\n",
      " Value of i is : 32\n",
      "F1 score for test data is :  0.9687500000000001\n",
      "Accuracy score for test data is :  0.9596977329974811\n",
      "train_test_split_ratio is :  0.33\n",
      " Value of i is : 33\n",
      "F1 score for test data is :  0.9685314685314687\n",
      "Accuracy score for test data is :  0.9559902200488998\n",
      "train_test_split_ratio is :  0.34\n",
      " Value of i is : 34\n",
      "F1 score for test data is :  0.9690346083788707\n",
      "Accuracy score for test data is :  0.9596199524940617\n",
      "train_test_split_ratio is :  0.35000000000000003\n",
      " Value of i is : 35\n",
      "F1 score for test data is :  0.9522184300341298\n",
      "Accuracy score for test data is :  0.9353348729792148\n",
      "train_test_split_ratio is :  0.36\n",
      " Value of i is : 36\n",
      "F1 score for test data is :  0.9551282051282051\n",
      "Accuracy score for test data is :  0.9370786516853933\n",
      "train_test_split_ratio is :  0.37\n",
      " Value of i is : 37\n",
      "F1 score for test data is :  0.9628432956381261\n",
      "Accuracy score for test data is :  0.949671772428884\n",
      "train_test_split_ratio is :  0.38\n",
      " Value of i is : 38\n",
      "F1 score for test data is :  0.9763779527559057\n",
      "Accuracy score for test data is :  0.9680170575692963\n",
      "train_test_split_ratio is :  0.39\n",
      " Value of i is : 39\n",
      "F1 score for test data is :  0.9727272727272728\n",
      "Accuracy score for test data is :  0.9625779625779626\n",
      "train_test_split_ratio is :  0.4\n",
      " Value of i is : 40\n",
      "F1 score for test data is :  0.978978978978979\n",
      "Accuracy score for test data is :  0.9716024340770791\n",
      "train_test_split_ratio is :  0.41000000000000003\n",
      " Value of i is : 41\n",
      "F1 score for test data is :  0.9655172413793104\n",
      "Accuracy score for test data is :  0.9524752475247524\n",
      "train_test_split_ratio is :  0.42\n",
      " Value of i is : 42\n",
      "F1 score for test data is :  0.967741935483871\n",
      "Accuracy score for test data is :  0.9574468085106383\n",
      "train_test_split_ratio is :  0.43\n",
      " Value of i is : 43\n",
      "F1 score for test data is :  0.961593172119488\n",
      "Accuracy score for test data is :  0.9489603024574669\n",
      "train_test_split_ratio is :  0.44\n",
      " Value of i is : 44\n",
      "F1 score for test data is :  0.9627586206896552\n",
      "Accuracy score for test data is :  0.9500924214417745\n",
      "train_test_split_ratio is :  0.45\n",
      " Value of i is : 45\n",
      "F1 score for test data is :  0.9709762532981531\n",
      "Accuracy score for test data is :  0.9602169981916817\n",
      "train_test_split_ratio is :  0.46\n",
      " Value of i is : 46\n",
      "F1 score for test data is :  0.9790575916230366\n",
      "Accuracy score for test data is :  0.9716814159292035\n",
      "train_test_split_ratio is :  0.47000000000000003\n",
      " Value of i is : 47\n",
      "F1 score for test data is :  0.9619921363040629\n",
      "Accuracy score for test data is :  0.949740034662045\n",
      "train_test_split_ratio is :  0.48\n",
      " Value of i is : 48\n",
      "F1 score for test data is :  0.9614395886889461\n",
      "Accuracy score for test data is :  0.9490662139219015\n",
      "train_test_split_ratio is :  0.49\n",
      " Value of i is : 49\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "# 5. Fifth train the model without the Qchat-10-Score variable on the combined\n",
    "#    dataset and validate our model on the combined data set.\n",
    "###########################################################################################################################\n",
    "\n",
    "for i in range(10,50):\n",
    "    df1 =  pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')\n",
    "    df1.drop('Qchat_10_Score',axis = 1, inplace=True)\n",
    "    train_model1(df1, test_size=i*0.01)\n",
    "    print(\" Value of i is :\", i)\n",
    "\n",
    "###########################################################################################################33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d66e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc =  pd.read_csv(r'../../data/pre_processed/combined_data_one_hot_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7938de07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "       'Qchat_10_Score', 'target', 'dataset', 'Sex_m', 'Ethnicity_Black',\n",
       "       'Ethnicity_Hispanic', 'Ethnicity_Latino', 'Ethnicity_Middle Eastern',\n",
       "       'Ethnicity_Mixed', 'Ethnicity_Native Indian', 'Ethnicity_Others',\n",
       "       'Ethnicity_Pacifica', 'Ethnicity_South Asian',\n",
       "       'Ethnicity_White European', 'Ethnicity_asian', 'Ethnicity_black',\n",
       "       'Ethnicity_middle eastern', 'Ethnicity_mixed', 'Ethnicity_south asian',\n",
       "       'Jaundice_Yes', 'Jaundice_no', 'Jaundice_yes',\n",
       "       'Family_mem_with_ASD_Yes', 'Family_mem_with_ASD_no',\n",
       "       'Family_mem_with_ASD_yes', 'Who_completed_the_test_Family member',\n",
       "       'Who_completed_the_test_Health Care Professional',\n",
       "       'Who_completed_the_test_Health care professional',\n",
       "       'Who_completed_the_test_Others', 'Who_completed_the_test_Self',\n",
       "       'Who_completed_the_test_family member'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b98b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc[['Qchat_10_Score','target']]\n",
    "df_1 = df[df['target']==1]\n",
    "df_0 = df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffc616ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Qchat_10_Score  target\n",
       " count      807.000000   807.0\n",
       " mean         6.785626     1.0\n",
       " std          1.987527     0.0\n",
       " min          0.000000     1.0\n",
       " 25%          5.000000     1.0\n",
       " 50%          7.000000     1.0\n",
       " 75%          8.000000     1.0\n",
       " max         10.000000     1.0,\n",
       "        Qchat_10_Score  target\n",
       " count      394.000000   394.0\n",
       " mean         2.101523     0.0\n",
       " std          1.906157     0.0\n",
       " min          0.000000     0.0\n",
       " 25%          1.000000     0.0\n",
       " 50%          2.000000     0.0\n",
       " 75%          3.000000     0.0\n",
       " max         10.000000     0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.describe(), df_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8cf0e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    807\n",
       "0    394\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8077ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7     150\n",
       " 5     128\n",
       " 4     115\n",
       " 8     109\n",
       " 6     108\n",
       " 9     106\n",
       " 10     85\n",
       " 0       4\n",
       " 1       2\n",
       " Name: Qchat_10_Score, dtype: int64,\n",
       " 3     117\n",
       " 1     103\n",
       " 2      99\n",
       " 0      55\n",
       " 10     12\n",
       " 6       3\n",
       " 9       3\n",
       " 4       1\n",
       " 7       1\n",
       " Name: Qchat_10_Score, dtype: int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['Qchat_10_Score'].value_counts(), df_0['Qchat_10_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3a7d4",
   "metadata": {},
   "source": [
    "#  Further actions to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b9782",
   "metadata": {},
   "source": [
    "#### 1. Remove outliers from 'Qchat_10_Score' variable for both yes(1) and no (0).\n",
    "#### 2. Read the criteria for the scoring 'Qchat_10_Score' variable in both the datasets and see if we can do any further data cleaning.\n",
    "#### 3. Include the data upto maybe 5 years (60 months) instead of the present 3 years (36months) as one participant pointed out that its important to observe the child upto 5 years. Need to verify this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abf9e4",
   "metadata": {},
   "source": [
    "# ----------------------------------------------  Thank You!   -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sril_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "043f27b72eea39df09a049984cc3cb1e23a5713445e4deb21abfcd96560d9e54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
