{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://asd.talkbank.org/access/English/Nadig.html \n",
        "\n",
        "Nadig is one of the datasets used in the paper: Detecting Autism Spectrum Disorders with Machine Learning Models Using Speech Transcripts -2021- Vikram Ramesh\n",
        "\n",
        "The goal of that project was to examine word learning in ASD children and typically-developing children. The study collected natural language samples during parent-child interaction during a freeplay task in which the parent and child played with a set of toys for approximately 10 minutes.\n",
        "\n",
        "Ages of children with ASD range from 36 – 74 months. Ages of typical children range from 12 – 57 months\n",
        "\n",
        "Odd numbered files (i.e., 101) = TYP children; Even numbered files = ASD children. A typical file format is 1**.cha"
      ],
      "metadata": {
        "id": "4GwqLZmPFfUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2CZMJBd6Ucg",
        "outputId": "c4ed5955-4e96-4199-9f0b-13a9884336a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Optional: move to the desired location:\n",
        "#%cd drive/My Drive/DIRECTORY_IN_YOUR_DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pylangacq"
      ],
      "metadata": {
        "id": "F3cX_xX16fQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5073fb19-f0cb-4b8d-a8c7-c7bf18fe1561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pylangacq in /usr/local/lib/python3.8/dist-packages (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from pylangacq) (2.25.1)\n",
            "Requirement already satisfied: tabulate[widechars]>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from pylangacq) (0.8.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.0->pylangacq) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.0->pylangacq) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.0->pylangacq) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18.0->pylangacq) (4.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pylangacq\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "_bF6PGOg6tkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"drive/My Drive/Omdena/SriLanka/Autism/asd_talkbank/Nadig.zip\"\n",
        "nadig = pylangacq.read_chat(url )\n",
        "nadig.n_files() #how many chat files are present for this data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3FOCoNb6wrf",
        "outputId": "f630a35c-8d4a-4216-a9ee-2d0c1e656b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Raw Data"
      ],
      "metadata": {
        "id": "khjSwEMTCTEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = nadig.file_paths() #file names will be used for later csv file-saving.\n",
        "file_names = [file_name.split('/')[1].split('.')[0] for file_name in file_names] #extract the file name from the path\n",
        "#file name has format nadig/101.cha . So, we split on '/', take the later part(101.cha). Again we split on '.' and take the first part '101'."
      ],
      "metadata": {
        "id": "m5zauKiAQR2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlN1aYy8QhiQ",
        "outputId": "b15d9659-75c6-4cfc-cfcb-a7a3d0e22aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size ='4'>Utterrance is a line of a conversation and its associated metadata such as token, timestamp, and grammatical info. Using utterrances(by_files=True) method here will return a 2d array of the format **(number_of_chat_files, number_of_utterrance_object_in_that_file)**</font>"
      ],
      "metadata": {
        "id": "ZlefM2ZBEUgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utterrances = nadig.utterances( by_files=True)"
      ],
      "metadata": {
        "id": "Pq0NR_VlCVrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size ='4'>As an example, we take the utterrances of the first chat file denoted by index 0. It has a **participant** attribute indicating who's speaking and a dictionary named **tiers** that holds the original text and some additional grammatical info. We can thus extract the original text from **tiers** using the key of participant name.</font>"
      ],
      "metadata": {
        "id": "lqD21mkKE5SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_utterrances = utterrances[0]\n",
        "for utter in first_file_utterrances:\n",
        "  participant = utter.participant; participant_line = utter.tiers[participant]\n",
        "  #print(f'{participant} : {participant_line}')"
      ],
      "metadata": {
        "id": "bfxN6uFRDbTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size ='4'>We will save each conversation in file_name.csv file. So, for chat file 101.cha we will have 101.csv. The csv data columns will be participant, sentence</font>"
      ],
      "metadata": {
        "id": "KSkry75eRGg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['participant', 'sentence']\n",
        "save_dir = \"drive/My Drive/Omdena/SriLanka/Autism/asd_talkbank/nadig\"\n",
        "chat_file_index = 0\n",
        "for chat_file in utterrances:\n",
        "  chat_df = pd.DataFrame(columns=column_names)\n",
        "  #print(chat_df)\n",
        "  for utter in chat_file:\n",
        "    participant = utter.participant; participant_line = utter.tiers[participant]\n",
        "    chat_df = chat_df.append({'participant':participant, 'sentence':participant_line}, ignore_index=True)\n",
        "  file_name = file_names[chat_file_index]; chat_file_index += 1\n",
        "  file_name = file_name + '.csv'\n",
        "  chat_df.to_csv(os.path.join(save_dir, file_name), index = False)\n",
        "  print(f'{chat_file_index}: {file_name}')\n",
        "  #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzN8xNwHCxOn",
        "outputId": "44cefffa-1da4-48f6-a421-d4d167bb4f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: 101.csv\n",
            "2: 102.csv\n",
            "3: 103.csv\n",
            "4: 104.csv\n",
            "5: 108.csv\n",
            "6: 109.csv\n",
            "7: 110.csv\n",
            "8: 111.csv\n",
            "9: 115.csv\n",
            "10: 117.csv\n",
            "11: 119.csv\n",
            "12: 120.csv\n",
            "13: 121.csv\n",
            "14: 122.csv\n",
            "15: 123.csv\n",
            "16: 124.csv\n",
            "17: 125.csv\n",
            "18: 126.csv\n",
            "19: 127.csv\n",
            "20: 128.csv\n",
            "21: 132.csv\n",
            "22: 133.csv\n",
            "23: 134.csv\n",
            "24: 135.csv\n",
            "25: 138.csv\n",
            "26: 139.csv\n",
            "27: 140.csv\n",
            "28: 141.csv\n",
            "29: 143.csv\n",
            "30: 145.csv\n",
            "31: 149.csv\n",
            "32: 157.csv\n",
            "33: 159.csv\n",
            "34: 161.csv\n",
            "35: 163.csv\n",
            "36: 165.csv\n",
            "37: 167.csv\n",
            "38: 169.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size ='4'>So, the data directory will now have 38 csv files for the 38 chat files in the original Nadig dataset.</font>"
      ],
      "metadata": {
        "id": "HLYtUtOdVf-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#file_names"
      ],
      "metadata": {
        "id": "NE2tHdbNSom-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}