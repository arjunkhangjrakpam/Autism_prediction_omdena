{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://asd.talkbank.org/access/English/Eigsti.html\n",
    "\n",
    "Associated dataset paper link: https://asd.talkbank.org/access/0docs/Eigsti2007.pdf\n",
    "\n",
    "- The files consist of transcribed 30-minute free play sessions of children ages 3-6 years, with ASD, non-ASD developmental delay, and typical development (n=16 per group)[48 files in total].\n",
    "- The first 100 utterances for each participant were included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../../../data/talkbank/Rollins.zip'\n",
    "rollins = pla.read_chat(url)\n",
    "rollins.n_files() #how many chat files are present for this data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = rollins.file_paths() #file names will be used for later csv file-saving.\n",
    "file_names = [file_name.split('\\\\')[1].split('.')[0] for file_name in file_names] #extract the file name from the path\n",
    "#file name has format eigsti/101.cha . So, we split on '/', take the later part(101.cha). Again we split on '.' and take the first part '101'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utterrance is a line of a conversation and its associated metadata such as token, timestamp, and grammatical info. Using utterrances(by_files=True) method here will return a 2d array of the format **(number_of_chat_files, number_of_utterrance_object_in_that_file)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterrances = rollins.utterances( by_files=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we take the utterrances of the first chat file denoted by index 0. It has a **participant** attribute indicating who's speaking and a dictionary named **tiers** that holds the original text and some additional grammatical info. We can thus extract the original text from **tiers** using the key of participant name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_utterrances = utterrances[0]\n",
    "for utter in first_file_utterrances:\n",
    "  participant = utter.participant; participant_line = utter.tiers[participant]\n",
    "  print(f'{participant} : {participant_line}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save each conversation in file_name.csv file. So, for chat file **1010.cha** we will have **1010.csv**. The csv data columns will be:\n",
    "- participant\n",
    "- sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['participant', 'sentence']\n",
    "save_dir = 'eigsti/'\n",
    "chat_file_index = 0\n",
    "for chat_file in utterrances:\n",
    "  chat_df = pd.DataFrame(columns=column_names)\n",
    "  #print(chat_df)\n",
    "  for utter in chat_file:\n",
    "    participant = utter.participant; participant_line = utter.tiers[participant] #extract participant and chat data info from the utterrance object\n",
    "    chat_df = chat_df.append({'participant':participant, 'sentence':participant_line}, ignore_index=True) #add the sentence and participant info to a df object\n",
    "  file_name = file_names[chat_file_index]; chat_file_index += 1\n",
    "  file_name = file_name + '.csv' #construct the file name of the csv file\n",
    "  chat_df.to_csv(os.path.join(save_dir, file_name), index = False) # save the csv file in the destination folder\n",
    "  print(f'{chat_file_index}: {file_name}')\n",
    "  #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chat_to_csv(utterances, file_names, save_dir='eigsti/', column_names=['participant', 'sentence']):\n",
    "    chat_file_index = 0\n",
    "    for chat_file in utterances:\n",
    "        chat_df = pd.DataFrame(columns=column_names)\n",
    "        for utter in chat_file:\n",
    "            participant = utter.participant\n",
    "            participant_line = utter.tiers[participant]\n",
    "            chat_df = chat_df.append({'participant': participant, 'sentence': participant_line}, ignore_index=True)\n",
    "        file_name = file_names[chat_file_index]\n",
    "        chat_file_index += 1\n",
    "        file_name = file_name + '.csv'\n",
    "        chat_df.to_csv(os.path.join(save_dir, file_name), index=False)\n",
    "        print(f'{chat_file_index}: {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../../../data/talkbank/Flusberg.zip'\n",
    "flusberg = pla.read_chat(url)\n",
    "flusberg.n_files() #how many chat files are present for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names2 = flusberg.file_paths() #file names will be used for later csv file-saving.\n",
    "file_names2 = [file_name.split('\\\\')[1].split('.')[0] for file_name in file_names2] #extract the file name from the path\n",
    "#file name has format eigsti/101.cha . So, we split on '/', take the later part(101.cha). Again we split on '.' and take the first part '101'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterrances2 = flusberg.utterances( by_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_utterrances2 = utterrances2[0]\n",
    "for utter in first_file_utterrances2:\n",
    "  participant = utter.participant; participant_line = utter.tiers[participant]\n",
    "  print(f'{participant} : {participant_line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['participant', 'sentence']\n",
    "save_dir = 'flusberg/'\n",
    "chat_file_index = 0\n",
    "for chat_file in utterrances2:\n",
    "  chat_df = pd.DataFrame(columns=column_names)\n",
    "  #print(chat_df)\n",
    "  for utter in chat_file:\n",
    "    participant = utter.participant; participant_line = utter.tiers[participant] #extract participant and chat data info from the utterrance object\n",
    "    chat_df = chat_df.append({'participant':participant, 'sentence':participant_line}, ignore_index=True) #add the sentence and participant info to a df object\n",
    "  file_name = file_names[chat_file_index]; chat_file_index += 1\n",
    "  file_name = file_name + '.csv' #construct the file name of the csv file\n",
    "  chat_df.to_csv(os.path.join(save_dir, file_name), index = False) # save the csv file in the destination folder\n",
    "  print(f'{chat_file_index}: {file_name}')\n",
    "  #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollins.headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(eigsti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigsti.ages(months=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = eigsti.words()\n",
    "words_by_files = eigsti.words(by_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words_one_file in words_by_files:\n",
    "    print(len(words_one_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigsti.utterances()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigsti.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = eigsti.word_frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigsti.mlu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigsti.headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zip_to_csv(url, folder_name):\n",
    "    chat = pla.read_chat(url)\n",
    "\n",
    "    file_names = chat.file_paths()\n",
    "    file_names = [file_name.split('\\\\')[1].split('.')[0] for file_name in file_names]\n",
    "\n",
    "    utterrances = chat.utterances( by_files=True)\n",
    "    column_names = ['participant', 'sentence']\n",
    "    save_dir = folder_name\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    chat_file_index = 0\n",
    "    for chat_file in utterrances:\n",
    "        chat_df = pd.DataFrame(columns=column_names)\n",
    "        for utter in chat_file:\n",
    "            participant = utter.participant\n",
    "            participant_line = utter.tiers[participant]\n",
    "            chat_df = chat_df.append({'participant':participant, 'sentence':participant_line}, ignore_index=True)\n",
    "        file_name = file_names[chat_file_index]\n",
    "        chat_file_index += 1\n",
    "        file_name = file_name + '.csv'\n",
    "        chat_df.to_csv(os.path.join(save_dir, file_name), index = False)\n",
    "        print(f'{chat_file_index}: {file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zip_to_csv('../../../data/talkbank/Eigsti.zip', 'eigsti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zip_to_csv('../../../data/talkbank/Nadig.zip', 'nadig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zip_to_csv('../../../data/talkbank/QuigleyMcNally.zip', 'quigley_mcNally')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zip_to_csv('../../../data/talkbank/Flusberg.zip', 'flusbeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zip_to_csv('../../../data/talkbank/Rollins.zip', 'rollins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sril_chat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "344fa07b0f53ceb7fb1173d4bfaec512179a5d0df4f5e1ecc536e12cb03adb4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
